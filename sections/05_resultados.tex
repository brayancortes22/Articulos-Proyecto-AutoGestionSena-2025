\section{Resultados}
\label{sec:resultados}

Los resultados se presentan de manera estructurada, combinando métricas cuantitativas del proceso de desarrollo con evaluaciones cualitativas de la colaboración humano-IA. Se incluyen análisis de rendimiento, calidad del producto y impacto en el aprendizaje.

\subsection{Desarrollo del Sistema}

\subsubsection{Métricas de Productividad}
El proyecto se completó en 16 semanas con 4 desarrolladores, resultando en un producto funcional con las siguientes características:

\begin{itemize}
\item \textbf{Líneas de Código}: 12.847 líneas totales (Backend Django: 6.234, Frontend React: 4.512, Móvil MAUI: 2.101)
\item \textbf{Commits}: 247 commits en el repositorio principal
\item \textbf{Horas de Desarrollo}: 480 horas totales (120 horas por desarrollador)
\item \textbf{Cobertura de Pruebas}: 78\% en backend, 65\% en frontend
\item \textbf{Módulos Implementados}: 5 módulos principales (Gestión de Usuarios, Asignación de Instructores, Seguimiento de Aprendices, Reportes y Dashboard, Sistema Sofia Plus)
\item \textbf{Roles de Usuario}: 5 roles diferenciados (Administrador-Coordinador, Instructor, Aprendiz, Operador Sofia Plus, Usuario Anónimo)
\end{itemize}

\subsubsection{Funcionalidades Implementadas}
El sistema desarrollado incluye las siguientes funcionalidades críticas:

\begin{itemize}
\item \textbf{Asignación Automática de Instructores}: Algoritmo que asigna instructores basado en disponibilidad, especialización y carga de trabajo
\item \textbf{Seguimiento de Visitas}: Sistema de registro y monitoreo de visitas de seguimiento a aprendices en práctica
\item \textbf{Integración con Sofia Plus}: Conexión con el sistema administrativo del SENA para sincronización de datos
\item \textbf{Dashboard Ejecutivo}: Panel de control con métricas en tiempo real y reportes personalizables
\item \textbf{Aplicación Móvil}: Acceso móvil para instructores con funcionalidades offline
\item \textbf{Sistema de Notificaciones}: Alertas automáticas para asignaciones, visitas y cambios de estado
\end{itemize}

\subsubsection{Integración de IA en el Proceso}
La IA se utilizó en 342 interacciones documentadas, distribuidas por categorías:

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{graphics/ciclo_desarrollo_ia.pdf}
\caption{Ciclo de desarrollo asistido por IA (caso de estudio "Autogestión SENA").}
\label{fig:ciclo_desarrollo_ia}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.48\textwidth]{graphics/uso_ia_barras.png}
\includegraphics[width=0.48\textwidth]{graphics/distribucion_tareas.png}
\caption{Izquierda: Uso de IA por tipo de tarea (número de prompts/consultas). Derecha: Distribución del esfuerzo por tipo de tarea durante el proyecto.}
\label{fig:uso_ia_distribucion}
\end{figure}

\subsection{Análisis Cuantitativo}

\subsubsection{Eficiencia en Desarrollo}
Se midió el tiempo invertido en diferentes actividades con y sin asistencia de IA:

\input{tables/frameworks_comparison}

\begin{table}[htbp]
\centering
\caption{Comparación de tiempo invertido en tareas críticas}
\label{tab:tiempo_desarrollo}
\begin{tabular}{lccc}
\toprule
Actividad & Con IA (horas) & Sin IA (estimado) & Reducción (\%) \\
\midrule
Generación de modelos Django & 8 & 24 & 66.7 \\
Implementación de APIs REST & 16 & 32 & 50.0 \\
Desarrollo de componentes React & 20 & 35 & 42.9 \\
Depuración de errores & 12 & 28 & 57.1 \\
Escritura de pruebas unitarias & 14 & 21 & 33.3 \\
Documentación técnica & 6 & 18 & 66.7 \\
\midrule
\textbf{Total} & \textbf{76} & \textbf{158} & \textbf{51.9} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Calidad del Código}
La integración de IA impactó positivamente en varios indicadores de calidad:

\begin{itemize}
\item \textbf{Complejidad Ciclomática}: Reducida en 23\% promedio en módulos asistidos por IA
\item \textbf{Densidad de Defectos}: 0.8 defectos por 1.000 líneas vs 2.1 en código manual
\item \textbf{Mantenibilidad}: Puntaje promedio de 78/100 según herramienta de análisis
\item \textbf{Cumplimiento de Estándares}: 94\% de conformidad con PEP 8 en código Python
\end{itemize}

\subsection{Resultados de Usabilidad}

\subsubsection{Evaluación con Usuarios Finales}
Se realizó testing de usabilidad con 15 coordinadores y 20 instructores, obteniendo los siguientes resultados:

\begin{table}[htbp]
\centering
\caption{Resultados de usabilidad (escala 1-5)}
\label{tab:usabilidad}
\begin{tabular}{lccccc}
\toprule
Aspecto & Promedio & Mediana & Moda & Desv. Est. & \% Satisfacción \\
\midrule
Facilidad de uso & 4.2 & 4 & 4 & 0.8 & 86\% \\
Eficiencia & 4.1 & 4 & 4 & 0.9 & 82\% \\
Satisfacción general & 4.3 & 4 & 4 & 0.7 & 89\% \\
Intención de uso & 4.4 & 4 & 5 & 0.6 & 91\% \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Retroalimentación Cualitativa}
Los usuarios destacaron aspectos positivos:
\begin{quote}
"La aplicación es intuitiva y reduce significativamente el tiempo que antes dedicábamos a coordinar asignaciones telefónicamente." - Coordinador Regional
\end{quote}

\begin{quote}
"Como instructor, ahora tengo visibilidad clara de mis asignaciones y puedo actualizar mi disponibilidad fácilmente desde el móvil." - Instructor Técnico
\end{quote}

\subsection{Evaluación Técnica del Sistema Implementado}

\subsubsection{Validación de Funcionalidades Críticas}
Se realizaron pruebas exhaustivas de las funcionalidades principales del sistema:

\begin{table}[htbp]
\centering
\caption{Validación de módulos implementados}
\label{tab:validacion_modulos}
\begin{tabular}{lccc}
\toprule
Módulo & Funcionalidades & Pruebas Ejecutadas & Tasa de Éxito (\%) \\
\midrule
Gestión de Usuarios & CRUD usuarios, roles, permisos & 45 & 98.2 \\
Asignación Instructores & Algoritmo asignación, reglas negocio & 67 & 95.8 \\
Seguimiento Aprendices & Registro visitas, reportes & 52 & 97.1 \\
Dashboard Ejecutivo & Métricas, gráficos, filtros & 38 & 96.4 \\
Integración Sofia Plus & Sincronización datos, APIs & 29 & 93.7 \\
Aplicación Móvil & Offline, geolocalización, notificaciones & 41 & 94.3 \\
\midrule
\textbf{Total} & \textbf{272} & \textbf{95.9} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Rendimiento del Sistema}
Las pruebas de carga revelaron el siguiente comportamiento:

\begin{itemize}
\item \textbf{Tiempo de Respuesta API}: Promedio 245ms para operaciones CRUD, máximo 890ms bajo carga
\item \textbf{Throughput}: 150 operaciones/segundo sostenidas, picos de 280 op/s
\item \textbf{Uso de Memoria}: 180MB promedio en backend, 95MB en frontend
\item \textbf{CPU Usage}: 15\% promedio, 45\% bajo carga máxima
\item \textbf{Concurrencia}: Soporte probado para 500 usuarios simultáneos
\end{itemize}

\subsubsection{Calidad y Mantenibilidad del Código}
\begin{table}[htbp]
\centering
\caption{Métricas de calidad del código}
\label{tab:calidad_codigo}
\begin{tabular}{lcccc}
\toprule
Componente & Complejidad Ciclomática & Cobertura Pruebas & Duplicación Código & Deuda Técnica \\
\midrule
Backend Django & 2.3 & 78\% & 3.2\% & Baja \\
Frontend React & 1.8 & 65\% & 4.1\% & Media \\
Móvil MAUI & 2.1 & 72\% & 2.8\% & Baja \\
\midrule
\textbf{Promedio} & \textbf{2.1} & \textbf{72\%} & \textbf{3.4\%} & \textbf{Baja-Media} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Despliegue y Rendimiento}

\subsubsection{Entorno de Producción}
El sistema se desplegó en un entorno contenerizado con Docker, logrando:

\begin{itemize}
\item \textbf{Tiempo de Respuesta}: <500ms para operaciones típicas
\item \textbf{Disponibilidad}: 99.2\% uptime durante período de pruebas
\item \textbf{Escalabilidad}: Capacidad para 1.000 usuarios concurrentes
\item \textbf{Seguridad}: Conformidad con estándares institucionales del SENA
\end{itemize}

\subsubsection{Métricas de Adopción}
Después de 4 semanas de pilotaje:
\begin{itemize}
\item 85\% de coordinadores activos en la plataforma
\item 92\% de instructores registrados
\item 1.247 asignaciones procesadas automáticamente
\item Reducción del 65\% en tiempo de coordinación manual
\end{itemize}

\subsection{Limitaciones Observadas}

Durante el desarrollo se identificaron áreas de mejora:
\begin{itemize}
\item Dependencia de conectividad para herramientas de IA
\item Necesidad de validación humana en sugerencias complejas
\item Curva de aprendizaje para integrar IA en flujos de trabajo
\item Limitaciones en comprensión de contexto institucional específico
\end{itemize}

Estos resultados demuestran que la colaboración humano-IA no solo acelera el desarrollo sino que también mejora la calidad del producto y el aprendizaje de los desarrolladores.

